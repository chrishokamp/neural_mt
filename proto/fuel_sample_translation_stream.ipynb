{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "import os\n",
    "import codecs\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import codecs\n",
    "import tempfile\n",
    "import cPickle\n",
    "import os\n",
    "import copy\n",
    "from collections import OrderedDict\n",
    "\n",
    "from fuel.datasets import H5PYDataset\n",
    "from picklable_itertools import iter_, chain\n",
    "from fuel.datasets import Dataset\n",
    "from fuel.datasets import TextFile\n",
    "from fuel.schemes import ConstantScheme\n",
    "from fuel.streams import DataStream\n",
    "from fuel.transformers import (\n",
    "    Merge, Batch, Filter, Padding, SortMapping, Unpack, Mapping)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from theano import tensor\n",
    "from toolz import merge\n",
    "import numpy\n",
    "import pickle\n",
    "from subprocess import Popen, PIPE\n",
    "import codecs\n",
    "\n",
    "from blocks.algorithms import (GradientDescent, StepClipping,\n",
    "                               CompositeRule, Adam, AdaDelta)\n",
    "from blocks.extensions import FinishAfter, Printing, Timing\n",
    "from blocks.extensions.monitoring import TrainingDataMonitoring\n",
    "from blocks.filter import VariableFilter\n",
    "from blocks.graph import ComputationGraph, apply_noise, apply_dropout\n",
    "from blocks.initialization import IsotropicGaussian, Orthogonal, Constant\n",
    "from blocks.main_loop import MainLoop\n",
    "from blocks.model import Model\n",
    "from blocks.select import Selector\n",
    "from blocks.search import BeamSearch\n",
    "from blocks_extras.extensions.plot import Plot\n",
    "\n",
    "from machine_translation.checkpoint import CheckpointNMT, LoadNMT\n",
    "from machine_translation.model import BidirectionalEncoder, Decoder\n",
    "from machine_translation.sampling import BleuValidator, Sampler, SamplingBase\n",
    "from machine_translation.stream import (get_tr_stream, get_dev_stream,\n",
    "                                        _ensure_special_tokens)\n",
    "\n",
    "\n",
    "from nnqe.dataset.preprocess import whitespace_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a fuel stream which subclasses text file to create a stream which provides three sources: \n",
    "# (source, [samples], and BLEU scores)\n",
    "\n",
    "# going forward, this may not be the fastest way because the sampling and BLEU score computation can be time consuming\n",
    "# we should look at Fuel's read-ahead and cacheing capacity\n",
    "\n",
    "# TODO: stateful transformer which takes a stream and adds the sources ('samples', 'scores')\n",
    "# class Mapping(Transformer)\n",
    "# the mapping should be a callable which gets samples, then computes the sentence-level BLEU\n",
    "# score for each sample with respect to the reference\n",
    "\n",
    "# use this script to get sentence-level scores(?)\n",
    "# https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/mteval-v13a.pl\n",
    "\n",
    "# parameters\n",
    "# sample_func: function(num_samples=1) which takes source seq and outputs <num_samples> samples\n",
    "# score_func: function\n",
    "\n",
    "# TODO: how do they create simple test streams in the fuel tests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MTSampleStreamTransformer(object):\n",
    "    \"\"\"\n",
    "    Stateful transformer which takes a stream and adds the sources ('samples', 'scores')\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_func: function(num_samples=1) which takes source seq and outputs <num_samples> samples\n",
    "    score_func: function\n",
    "\n",
    "    At call time, we expect a stream providing (sources,) -- i.e. something like a TextFile object\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, sample_func, score_func):\n",
    "        self.sample_func = sample_func\n",
    "        self.score_func = score_func\n",
    "\n",
    "    def __call__(self, source_data):\n",
    "        return ([x for x in source_data[0]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fake_score(source, target):\n",
    "    return 1.\n",
    "\n",
    "def fake_sample(source):\n",
    "    return [[2,67,33,778,323,68], [545,5347,432,21,53,68,47,3689,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_transformer = MTSampleStreamTransformer(fake_sample, fake_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 55, 75, 324, 43, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_source = ([1,55,75,324,43,0],)\n",
    "\n",
    "test_transformer(fake_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Creating theano variables\n",
      "INFO:root:Building sampling model\n",
      "INFO:root:Creating Sampling Model...\n",
      "INFO:root:Loading parameters from model: /home/chris/projects/neural_mt/archived_models/BERTHA-TEST_Adam_wmt-multimodal_internal_data_dropout0.3_ff_noiseFalse_search_model_en2es_vocab20000_emb300_rec800_batch15/best_bleu_model_1455464992_BLEU31.61.npz\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800,)         : /bidirectionalencoder/bidirectionalwmt15/backward.initial_state\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (1600,)        : /bidirectionalencoder/back_fork/fork_gate_inputs.b\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (300, 1600)    : /bidirectionalencoder/back_fork/fork_gate_inputs.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800,)         : /bidirectionalencoder/back_fork/fork_inputs.b\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (300, 800)     : /bidirectionalencoder/back_fork/fork_inputs.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800,)         : /bidirectionalencoder/bidirectionalwmt15/forward.initial_state\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (1600,)        : /bidirectionalencoder/fwd_fork/fork_gate_inputs.b\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (300, 1600)    : /bidirectionalencoder/fwd_fork/fork_gate_inputs.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800,)         : /bidirectionalencoder/fwd_fork/fork_inputs.b\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (300, 800)     : /bidirectionalencoder/fwd_fork/fork_inputs.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800,)         : /decoder/sequencegenerator/att_trans/decoder/state_initializer/linear_0.b\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (20000, 300)   : /bidirectionalencoder/embeddings.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800, 1600)    : /bidirectionalencoder/bidirectionalwmt15/forward.state_to_gates\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800, 800)     : /bidirectionalencoder/bidirectionalwmt15/forward.state_to_state\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800, 1600)    : /bidirectionalencoder/bidirectionalwmt15/backward.state_to_gates\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800, 800)     : /bidirectionalencoder/bidirectionalwmt15/backward.state_to_state\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800, 800)     : /decoder/sequencegenerator/att_trans/decoder/state_initializer/linear_0.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800, 1600)    : /decoder/sequencegenerator/att_trans/decoder.state_to_gates\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (1600, 800)    : /decoder/sequencegenerator/att_trans/attention/preprocess.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800,)         : /decoder/sequencegenerator/att_trans/attention/preprocess.b\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800, 800)     : /decoder/sequencegenerator/att_trans/attention/state_trans/transform_states.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800, 1)       : /decoder/sequencegenerator/att_trans/attention/energy_comp/linear.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (1600, 1600)   : /decoder/sequencegenerator/att_trans/distribute/fork_gate_inputs.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800, 800)     : /decoder/sequencegenerator/readout/merge/transform_states.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (20000, 300)   : /decoder/sequencegenerator/readout/lookupfeedbackwmt15/lookuptable.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (300, 800)     : /decoder/sequencegenerator/readout/merge/transform_feedback.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (1600, 800)    : /decoder/sequencegenerator/readout/merge/transform_weighted_averages.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800,)         : /decoder/sequencegenerator/readout/initializablefeedforwardsequence/maxout_bias.b\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (400, 300)     : /decoder/sequencegenerator/readout/initializablefeedforwardsequence/softmax0.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (300, 20000)   : /decoder/sequencegenerator/readout/initializablefeedforwardsequence/softmax1.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (20000,)       : /decoder/sequencegenerator/readout/initializablefeedforwardsequence/softmax1.b\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (300, 1600)    : /decoder/sequencegenerator/fork/fork_gate_inputs.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (1600,)        : /decoder/sequencegenerator/fork/fork_gate_inputs.b\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800, 800)     : /decoder/sequencegenerator/att_trans/decoder.state_to_state\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (1600, 800)    : /decoder/sequencegenerator/att_trans/distribute/fork_inputs.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (300, 800)     : /decoder/sequencegenerator/fork/fork_inputs.W\n",
      "INFO:machine_translation.checkpoint: Loaded to CG (800,)         : /decoder/sequencegenerator/fork/fork_inputs.b\n",
      "INFO:machine_translation.checkpoint: Number of parameters loaded for computation graph: 37\n"
     ]
    }
   ],
   "source": [
    "# create the graph which can sample from our model \n",
    "# Note that we must sample instead of getting the 1-best, because we need the randomness to make the expected\n",
    "# BLEU score make sense\n",
    "# TODO: check on the parameterization of the softmax emitter sampler in blocks -- is softmax temperature implemented?\n",
    "\n",
    "exp_config = {\n",
    "    'src_vocab_size': 20000,\n",
    "    'trg_vocab_size': 20000,\n",
    "    'enc_embed': 300,\n",
    "    'dec_embed': 300,\n",
    "    'enc_nhids': 800,\n",
    "    'dec_nhids': 800,\n",
    "    'saved_parameters': '/home/chris/projects/neural_mt/archived_models/BERTHA-TEST_Adam_wmt-multimodal_internal_data_dropout'+\\\n",
    "    '0.3_ff_noiseFalse_search_model_en2es_vocab20000_emb300_rec800_batch15/best_bleu_model_1455464992_BLEU31.61.npz',\n",
    "    'src_vocab': '/home/chris/projects/neural_mt/archived_models/BERTHA-TEST_Adam_wmt-multimodal_internal_data_dropout0'+\\\n",
    "    '.3_ff_noiseFalse_search_model_en2es_vocab20000_emb300_rec800_batch15/vocab.en-de.en.pkl',\n",
    "    'trg_vocab': '/home/chris/projects/neural_mt/archived_models/BERTHA-TEST_Adam_wmt-multimodal_internal_data_dropout0'+\\\n",
    "    '.3_ff_noiseFalse_search_model_en2es_vocab20000_emb300_rec800_batch15/vocab.en-de.de.pkl',\n",
    "    'source_file': '/home/chris/projects/neural_mt/archived_models/BERTHA-TEST_Adam_wmt-multimodal_internal_data_dropout'+\\\n",
    "    '0.3_ff_noiseFalse_search_model_en2es_vocab20000_emb300_rec800_batch15/training_data/train.en.tok.shuf',\n",
    "    'unk_id':1\n",
    "}\n",
    "\n",
    "def get_sampling_model_and_input(exp_config):\n",
    "    # Create Theano variables\n",
    "    encoder = BidirectionalEncoder(\n",
    "        exp_config['src_vocab_size'], exp_config['enc_embed'], exp_config['enc_nhids'])\n",
    "\n",
    "    decoder = Decoder(\n",
    "        exp_config['trg_vocab_size'], exp_config['dec_embed'], exp_config['dec_nhids'],\n",
    "        exp_config['enc_nhids'] * 2)\n",
    "\n",
    "    # Create Theano variables\n",
    "    logger.info('Creating theano variables')\n",
    "    sampling_input = tensor.lmatrix('source')\n",
    "\n",
    "    # Get beam search\n",
    "    logger.info(\"Building sampling model\")\n",
    "    sampling_representation = encoder.apply(\n",
    "        sampling_input, tensor.ones(sampling_input.shape))\n",
    "    generated = decoder.generate(sampling_input, sampling_representation)\n",
    "\n",
    "#     _, samples = VariableFilter(\n",
    "#         bricks=[decoder.sequence_generator], name=\"outputs\")(\n",
    "#                  ComputationGraph(generated[1]))  # generated[1] is next_outputs\n",
    "#     beam_search = BeamSearch(samples=samples)\n",
    "\n",
    "    # build the model that will let us get a theano function from the sampling graph\n",
    "    logger.info(\"Creating Sampling Model...\")\n",
    "    sampling_model = Model(generated)\n",
    "\n",
    "    # Set the parameters from a trained models\n",
    "    logger.info(\"Loading parameters from model: {}\".format(exp_config['saved_parameters']))\n",
    "    # load the parameter values from an .npz file\n",
    "    param_values = LoadNMT.load_parameter_values(exp_config['saved_parameters'])\n",
    "    LoadNMT.set_model_parameters(sampling_model, param_values)\n",
    "    \n",
    "    return sampling_model, sampling_input\n",
    "\n",
    "test_model, theano_sampling_input = get_sampling_model_and_input(exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make TextFile stream for source data\n",
    "# Load dictionaries and ensure special tokens exist\n",
    "\n",
    "def get_source_stream(source_file=None, src_vocab=None, src_vocab_size=30000,\n",
    "                      unk_id=1, **kwargs):\n",
    "    \"\"\"Get a stream for source data\"\"\"\n",
    "    source_stream = None\n",
    "   \n",
    "    src_vocab = _ensure_special_tokens(\n",
    "        src_vocab if isinstance(src_vocab, dict) else\n",
    "        cPickle.load(open(src_vocab)),\n",
    "        bos_idx=0, eos_idx=src_vocab_size - 1, unk_idx=unk_id)\n",
    "    source_dataset = TextFile([source_file], src_vocab, bos_token=None)\n",
    "    source_stream = DataStream(source_dataset)\n",
    "    return source_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_source_stream = get_source_stream(**exp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_source_data = list(test_source_stream.get_epoch_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(test_source_data)\n",
    "a_few_instances = [numpy.array(i[0]) for i in test_source_data[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test that we can pull samples from the model\n",
    "test_sampling_func = test_model.get_theano_function()\n",
    "\n",
    "\n",
    "# def _get_true_length(self, seq, vocab):\n",
    "#     try:\n",
    "#         return seq.tolist().index(vocab['</S>']) + 1\n",
    "#     except ValueError:\n",
    "#         return len(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load src and target vocabs to validate samples\n",
    "src_vocab = cPickle.load(open(exp_config['src_vocab']))\n",
    "trg_vocab = cPickle.load(open(exp_config['trg_vocab']))\n",
    "src_vocab_size = exp_config['src_vocab_size'] - 1\n",
    "trg_vocab_size = exp_config['trg_vocab_size'] - 1\n",
    "\n",
    "\n",
    "src_vocab = _ensure_special_tokens(src_vocab, bos_idx=0,\n",
    "                                   eos_idx=src_vocab_size, unk_idx=exp_config['unk_id'])\n",
    "trg_vocab = _ensure_special_tokens(trg_vocab, bos_idx=0,\n",
    "                                   eos_idx=trg_vocab_size, unk_idx=exp_config['unk_id'])\n",
    "\n",
    "src_ivocab = {v:k for k,v in src_vocab.items()}\n",
    "trg_ivocab = {v:k for k,v in trg_vocab.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two boys in blue shirts sit on the end of a bench next to a fair ride . </S>\n",
      "Zwei Jungen in blauen Shirts sitzen am Ende einer Bank neben einem Fahrgeschäft in der Stadt . </S>\n",
      "A man pointing to the audience area on stage while holding a microphone with banjos behind him . </S>\n",
      "Ein Mann zeigt auf den Bereich ist auf die Bühne riss . </S>\n",
      "A little girl riding a two wheeler , wearing her helmet close to the street with passing cars . </S>\n",
      "Ein kleines Mädchen fährt auf einem zwei Fahrrädern , bei dem Verkehr auf der Straße in der Nähe ist viele Zeichen hindurch . </S>\n",
      "A road worker in green , there is an orange cone near him . </S>\n",
      "Eine Straße in grün , neben ihm befindet sich der Person . </S>\n",
      "A man leans against a building near a busy street . </S>\n",
      "Ein Mann lehnt an einem Gebäude in der Nähe einer stark befahrenen Straße . </S>\n",
      "Two boys in blue shirts sit on the end of a bench next to a fair ride . </S>\n",
      "Zwei Jungen in blauem Hemden sitzen am Ende einer kniet neben einem Fahrgeschäft in der Stadt . </S>\n",
      "A man pointing to the audience area on stage while holding a microphone with banjos behind him . </S>\n",
      "Ein Mann zeigt auf der Bühne auf von der Bühne von Gitarre , während ein Mikrofon hergeht . </S>\n",
      "A little girl riding a two wheeler , wearing her helmet close to the street with passing cars . </S>\n",
      "Ein kleines Mädchen fährt auf einem zwei Stangen , die in der Nähe hält für die Straße mit fahrenden Autos abgestellt sind . </S>\n",
      "A road worker in green , there is an orange cone near him . </S>\n",
      "Ein Straßenarbeiter in Grün , der ein orangefarbenes Reifen befinden . </S>\n",
      "A man leans against a building near a busy street . </S>\n",
      "Ein Mann fliegt an einem Gebäude neben einer stark befahrenen Straße . </S>\n",
      "Two boys in blue shirts sit on the end of a bench next to a fair ride . </S>\n",
      "Zwei Jungen in blauen Hemden sitzen am Ende einer Bank neben einem Fahrgeschäft in der Stadt . </S>\n",
      "A man pointing to the audience area on stage while holding a microphone with banjos behind him . </S>\n",
      "Ein Mann zeigt auf dem Schaufenster mit ein Mikrofon , hinter ihm sind ein Mikrofon . </S>\n",
      "A little girl riding a two wheeler , wearing her helmet close to the street with passing cars . </S>\n",
      "Ein kleines Mädchen fährt mit einem Fahrradhelm , Rädern an der Straße mit einem fahrenden Autos liegenden Stangen hindurch . </S>\n",
      "A road worker in green , there is an orange cone near him . </S>\n",
      "Ein grün gekleideter Straße , die eine orange Schale um sich von ihm im . </S>\n",
      "A man leans against a building near a busy street . </S>\n",
      "Ein Mann lehnt an einem Gebäude an der Straße in der Nähe von Rädern . </S>\n",
      "Two boys in blue shirts sit on the end of a bench next to a fair ride . </S>\n",
      "Zwei Jungen in blauem Hemden sitzen am Ende einer Bank neben einem Fahrgeschäft in der Nähe . </S>\n",
      "A man pointing to the audience area on stage while holding a microphone with banjos behind him . </S>\n",
      "Ein Schiedsrichter zeigt auf die Bühne auf den Bereich ist ab , während ihm umgedreht ein Labrador im stimmungsvollen blicken hoch . </S>\n",
      "A little girl riding a two wheeler , wearing her helmet close to the street with passing cars . </S>\n",
      "Ein kleines Mädchen fährt mit einem Zweirad einen Zweirad nahe der Straße neben Schildern mit Schildern ihres Autos hindurch . </S>\n",
      "A road worker in green , there is an orange cone near him . </S>\n",
      "Ein Straßenarbeiter in Grün ist eine orange Kegel neben ihm . </S>\n",
      "A man leans against a building near a busy street . </S>\n",
      "Ein Mann lehnt an einem Gebäude neben einer stark befahrenen Straße . </S>\n",
      "Two boys in blue shirts sit on the end of a bench next to a fair ride . </S>\n",
      "Zwei Jungen in grünen Hemden sitzen am Ende einer Bank neben einem Jahrmarkt . </S>\n",
      "A man pointing to the audience area on stage while holding a microphone with banjos behind him . </S>\n",
      "Ein Mann zeigt auf die Bühne nach einem Sessel und ein Mikrofon beobachtet es sind ab . </S>\n",
      "A little girl riding a two wheeler , wearing her helmet close to the street with passing cars . </S>\n",
      "Ein kleines Mädchen fährt mit ihrem Helm Fahrrad , die unter der Straße unten bewachsen ist . </S>\n",
      "A road worker in green , there is an orange cone near him . </S>\n",
      "Ein Straßenarbeiter in Grün ist eine orange Kegel sind am Abend fest . </S>\n",
      "A man leans against a building near a busy street . </S>\n",
      "Ein Mann lehnt sich an einem Gebäude in der Nähe einer stark befahrenen Straße . </S>\n"
     ]
    }
   ],
   "source": [
    "# inp = input_[i, :input_length]\n",
    "\n",
    "def _get_true_length(seq, vocab):\n",
    "    try:\n",
    "        return seq.tolist().index(vocab['</S>']) + 1\n",
    "    except ValueError:\n",
    "        return len(seq)\n",
    "\n",
    "# outputs of self.sampling_fn = outputs of sequence_generator.generate: next_states + [next_outputs] +\n",
    "#                 list(next_glimpses.values()) + [next_costs])\n",
    "num_samples = 5\n",
    "\n",
    "for _ in range(num_samples):\n",
    "    for source_seq in a_few_instances[:5]:\n",
    "        print(' '.join(src_ivocab[idx] for idx in source_seq))\n",
    "        _1, outputs, _2, _3, costs = test_sampling_func(source_seq[None, :])\n",
    "        # the output is a [seq_len, 1] array\n",
    "        outputs = outputs.reshape(outputs.shape[0])\n",
    "        outputs = outputs[:_get_true_length(outputs, trg_vocab)]\n",
    "        print(' '.join(trg_ivocab[idx] for idx in outputs))\n",
    "\n",
    "# TODO: can we get multiple outputs in one shot?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    outputs = outputs.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-16-f1dfc900db91>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-16-f1dfc900db91>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    self.multibleu_cmd = ['perl', self.config['bleu_script'],\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# calling the external scoring script\n",
    "    \n",
    "    self.multibleu_cmd = ['perl', self.config['bleu_script'],\n",
    "                              self.config['val_set_grndtruth'], '<']\n",
    "    \n",
    "    mb_subprocess = Popen(self.multibleu_cmd, stdin=PIPE, stdout=PIPE)\n",
    "    \n",
    "      mb_subprocess.stdin.flush()\n",
    "\n",
    "    \n",
    "     # Write to subprocess and file if it exists\n",
    "    print(trans_out, file=mb_subprocess.stdin)\n",
    "            \n",
    "            \n",
    "        # send end of file, read output.\n",
    "        mb_subprocess.stdin.close()\n",
    "        stdout = mb_subprocess.stdout.readline()\n",
    "        logger.info(stdout)\n",
    "        out_parse = re.match(r'BLEU = [-.0-9]+', stdout)\n",
    "        logger.info(\"Validation Took: {} minutes\".format(\n",
    "            float(time.time() - val_start_time) / 60.))\n",
    "        assert out_parse is not None\n",
    "\n",
    "        # extract the score\n",
    "        bleu_score = float(out_parse.group()[6:])\n",
    "        self.val_bleu_curve.append(bleu_score)\n",
    "        logger.info(bleu_score)\n",
    "        mb_subprocess.terminate()\n",
    "\n",
    "\n",
    "        return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model related -----------------------------------------------------------\n",
    "# Sequences longer than this will be discarded\n",
    "'seq_len': 40\n",
    "# Number of hidden units in encoder/decoder GRU\n",
    "'enc_nhids': &REC_SIZE 800\n",
    "'dec_nhids': 800\n",
    "\n",
    "# Dimension of the word embedding matrix in encoder/decoder\n",
    "'enc_embed': &EMBED_SIZE 300\n",
    "'dec_embed': 300\n",
    "\n",
    "# Optimization related ----------------------------------------------------\n",
    "# Batch size\n",
    "'batch_size': &BATCH_SIZE 15 \n",
    "\n",
    "# This many batches will be read ahead and sorted\n",
    "'sort_k_batches': 15 \n",
    "\n",
    "# Optimization step rule\n",
    "'step_rule': &STEP_RULE 'Adam'\n",
    "\n",
    "# Gradient clipping threshold\n",
    "'step_clipping': 1.\n",
    "\n",
    "# Std of weight initialization\n",
    "'weight_scale': 0.01\n",
    "\n",
    "# Regularization related --------------------------------------------------\n",
    "\n",
    "# Weight noise flag for feed forward layers\n",
    "'weight_noise_ff': &FF_NOISE False\n",
    "\n",
    "# Weight noise flag for recurrent layers\n",
    "'weight_noise_rec': False\n",
    "\n",
    "# Dropout ratio, applied only after readout maxout\n",
    "'dropout': &DROPOUT 0.3\n",
    "\n",
    "# Source and target vocabulary sizes, should include bos, eos, unk tokens\n",
    "'src_vocab_size': &SRC_VOCAB_SIZE 20000\n",
    "'trg_vocab_size': &TGT_VOCAB_SIZE 20000\n",
    "\n",
    "# Special tokens and indexes\n",
    "'unk_id': 1\n",
    "'bos_token': '<S>'\n",
    "'eos_token': '</S>'\n",
    "'unk_token': '<UNK>'\n",
    "\n",
    "# Root directory for dataset\n",
    "'datadir': &DATADIR /media/1tb_drive/multilingual-multimodal/flickr30k/train/processed\n",
    "\n",
    "# the name of the directory where the model will be saved and checkpointed\n",
    "#'model_save_directory': &SAVEDIR !format_str ['unbabel_data_dropout{}_ff_noise{}_search_model_en2es_vocab{}_emb{}_rec{}_batch{}', *DROPOUT, *FF_NOISE, *SRC_VOCAB_SIZE, *EMBED_SIZE, *REC_SIZE, *BATCH_SIZE]\n",
    "'model_save_directory': &SAVEDIR !format_str ['BERTHA-TEST_{}_wmt-multimodal_internal_data_dropout0.3_ff_noiseFalse_search_model_en2es_vocab20000_emb300_rec800_batch15', *STEP_RULE]\n",
    "\n",
    "# Where to save model, this corresponds to 'prefix' in groundhog\n",
    "'saveto': &OUTPUT_DIR !path_join [*DATADIR, *SAVEDIR]\n",
    "\n",
    "# Module name of the stream that will be used\n",
    "# note this requires the stream to be implemented as a module -- there may be a better way\n",
    "'stream': 'stream'\n",
    "\n",
    "# Source and target vocabularies\n",
    "'src_vocab': !path_join [*DATADIR, 'vocab.en-de.en.pkl']\n",
    "'trg_vocab': !path_join [*DATADIR, 'vocab.en-de.de.pkl']\n",
    "\n",
    "# Source and target datasets\n",
    "'src_data': !path_join [*DATADIR, 'train.en.tok.shuf']\n",
    "'trg_data': !path_join [*DATADIR, 'train.de.tok.shuf']\n",
    "\n",
    "\n",
    "# Early stopping based on BLEU score on dev set ------------------------------------\n",
    "\n",
    "# Normalize cost according to sequence length after beam-search\n",
    "'normalized_bleu': True\n",
    "\n",
    "# Bleu script that will be used (moses multi-perl in this case)\n",
    "'bleu_script': !path_join [*DATADIR, 'multi-bleu.perl']\n",
    "\n",
    "# Validation set source file\n",
    "'val_set': !path_join [*DATADIR, 'dev.en.tok']\n",
    "\n",
    "# Validation set gold file\n",
    "'val_set_grndtruth': !path_join [*DATADIR, 'dev.de.tok']\n",
    "\n",
    "# Print validation output to file\n",
    "'output_val_set': True\n",
    "\n",
    "# Validation output file\n",
    "'val_set_out': !path_join [*OUTPUT_DIR, 'validation_out.txt']\n",
    "\n",
    "# Beam-size\n",
    "'beam_size': 20 \n",
    "\n",
    "# Timing/monitoring related -----------------------------------------------\n",
    "\n",
    "# Maximum number of updates\n",
    "'finish_after': 1000000\n",
    "\n",
    "# Reload model from files if exist\n",
    "'reload': True\n",
    "\n",
    "# Save model after this many updates\n",
    "'save_freq': 5000\n",
    "\n",
    "# Show samples from model after this many updates\n",
    "'sampling_freq': 5000\n",
    "\n",
    "# Show this many samples at each sampling\n",
    "'hook_samples': 5\n",
    "\n",
    "# Validate bleu after this many updates\n",
    "'bleu_val_freq': 1000 \n",
    "\n",
    "# Start bleu validation after this many updates\n",
    "'val_burn_in': 5000\n",
    "\n",
    "# Using trained models for prediction ------------\n",
    "\n",
    "# The location of the saved parameters of a trained model as .npz\n",
    "'saved_parameters': ~\n",
    "\n",
    "# The location of a test set in the source language\n",
    "'test_set': ~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MTSampleStreamGenerator(Dataset):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source_files: list[str] - the files containing the source seqs we'll use to generate samples\n",
    "    sample_func: function(num_samples=1) which takes source seq and outputs <num_samples> samples\n",
    "    score_func: function\n",
    "    \n",
    "    # source dict only or source + target dict?\n",
    "    dictionary: dict mapping word-->id -- TODO: switch to parameterized choice\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    provides_sources = ('sources','targets', 'scores')\n",
    "    example_iteration_scheme = None\n",
    "\n",
    "    def __init__(self, files, dictionary, all_idxs_and_probs, bos_token=None, eos_token=None,\n",
    "                 unk_token='<UNK>', level='word', preprocess=None):\n",
    "        self.files = files\n",
    "        self.dictionary = dictionary\n",
    "        # use all idxs to choose random substitutions and insertions\n",
    "        # WORKING: switch to parameterized choice using word freq\n",
    "        # WORKING pass in two lists -- words and probs (use the p= kwarg from np.random.choice)\n",
    "        # self.all_idxs = dictionary.values()\n",
    "        self.all_idxs, self.all_probs = zip(*all_idxs_and_probs.items())\n",
    "        if bos_token is not None and bos_token not in dictionary:\n",
    "            raise ValueError\n",
    "        self.bos_token = bos_token\n",
    "        if eos_token is not None and eos_token not in dictionary:\n",
    "            raise ValueError\n",
    "        self.eos_token = eos_token\n",
    "        if unk_token not in dictionary:\n",
    "            raise ValueError\n",
    "        self.unk_token = unk_token\n",
    "        if level not in ('word', 'character'):\n",
    "            raise ValueError\n",
    "        self.level = level\n",
    "        self.preprocess = preprocess\n",
    "        super(RandomTargetGenerator, self).__init__()\n",
    "\n",
    "    def open(self):\n",
    "        return chain(*[iter_(open(f)) for f in self.files])\n",
    "\n",
    "    def get_data(self, state=None, request=None):\n",
    "        if request is not None:\n",
    "            raise ValueError\n",
    "        sentence = next(state)\n",
    "        if self.preprocess is not None:\n",
    "            sentence = self.preprocess(sentence)\n",
    "        pe_sequence = [self.dictionary[self.bos_token]] if self.bos_token else []\n",
    "        if self.level == 'word':\n",
    "            pe_sequence.extend(self.dictionary.get(word,\n",
    "                                            self.dictionary[self.unk_token])\n",
    "                        for word in sentence.split())\n",
    "        else:\n",
    "            pe_sequence.extend(self.dictionary.get(char,\n",
    "                                            self.dictionary[self.unk_token])\n",
    "                        for char in sentence.strip())\n",
    "        if self.eos_token:\n",
    "            pe_sequence.append(self.dictionary[self.eos_token])\n",
    "\n",
    "        # now use the pe sequence to generate artificial target_sequence and tag_sequence\n",
    "        target_sequence, tag_sequence = self._generate_artificial_target_and_tag_seqs(pe_sequence)\n",
    "\n",
    "        return (target_sequence, tag_sequence)\n",
    "\n",
    "    # TODO: currently only supports subs, not inserts\n",
    "    # TODO: tag identities are hard-coded as 0=BAD 1=OK\n",
    "    def _generate_artificial_target_and_tag_seqs(self, pe_sequence):\n",
    "        target_sequence = copy.copy(pe_sequence)\n",
    "        tag_sequence = [1] * len(pe_sequence)\n",
    "\n",
    "        # TODO: make num_subs distribution configurable\n",
    "        num_subs_to_make = numpy.random.randint(0, (int(numpy.ceil(len(pe_sequence / 1.3)))))\n",
    "        sub_idxs = numpy.random.choice(len(pe_sequence), size=num_subs_to_make)\n",
    "#         print('len orig seq: {}'.format(len(pe_sequence)))\n",
    "#         print('len orig seq / 2: {}'.format(len(pe_sequence) //2))\n",
    "#         print('n_subs: {}'.format(num_subs_to_make))\n",
    "#         print(sub_idxs)\n",
    "        for idx in sub_idxs:\n",
    "            new_word = numpy.random.choice(self.all_idxs, p=self.all_probs)\n",
    "            target_sequence[idx] = new_word\n",
    "            tag_sequence[idx] = 0\n",
    "\n",
    "        return target_sequence, tag_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
